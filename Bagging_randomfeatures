# we have a dataset with selected features (from randam features) we got by performing lgb and now we are doing baggy classifier on it
# # Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix

# storing the dataset in variable 
data = pd.read_csv('C:/Users/aashi/Downloads/Randam_Features.csv')

#fixing X and y
rfe_cols = ['Isoelectric_point', 'Aromaticity', 'AAC_C', 'AAC_G', 'AAC_H', 'AAC_N',
'AAC_Y', 'PCP_NC', 'PCP_NE', 'PCP_AL', 'PCP_HB', 'PCP_SS_HE',
'PCP_SA_EX', 'PCP_SA_IN', 'PCP_TN', 'PCP_SM', 'PCP_Z1', 'PCP_Z2',
'PCP_Z5','PAAC1_lam1']

X = data[rfe_cols]
y = data['Label']

# Split the data into training and testing sets (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Initialize BaggingClassifier
bagging_clf = BaggingClassifier(random_state=42)

# Fit the model
bagging_clf.fit(X_train, y_train)

# Predict on both training and testing data
y_train_pred = bagging_clf.predict(X_train)
y_test_pred = bagging_clf.predict(X_test)

# Define a function to calculate specificity
def specificity_score(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    return tn / (tn + fp)

# Calculate metrics for training data
train_metrics = {
    'Accuracy': accuracy_score(y_train, y_train_pred),
    'Precision': precision_score(y_train, y_train_pred),
    'Recall (Sensitivity)': recall_score(y_train, y_train_pred),
    'Specificity': specificity_score(y_train, y_train_pred),
    'MCC': matthews_corrcoef(y_train, y_train_pred),
    'F1 Score': f1_score(y_train, y_train_pred)
}

# Calculate metrics for testing data
test_metrics = {
    'Accuracy': accuracy_score(y_test, y_test_pred),
    'Precision': precision_score(y_test, y_test_pred),
    'Recall (Sensitivity)': recall_score(y_test, y_test_pred),
    'Specificity': specificity_score(y_test, y_test_pred),
    'MCC': matthews_corrcoef(y_test, y_test_pred),
    'F1 Score': f1_score(y_test, y_test_pred)
}

# Combine results into a DataFrame for better visualization
results_df = pd.DataFrame({'Training Data': train_metrics, 'Testing Data': test_metrics}).T

# Display the results
results_df

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef
)
import pandas as pd

# Load the dataset
file_path = 'C:/Users/aashi/Downloads/Randam_Features.csv'
data = pd.read_csv(file_path)

#fixing X and y
rfe_cols = ['Isoelectric_point', 'Aromaticity', 'AAC_C', 'AAC_G', 'AAC_H', 'AAC_N',
'AAC_Y', 'PCP_NC', 'PCP_NE', 'PCP_AL', 'PCP_HB', 'PCP_SS_HE',
'PCP_SA_EX', 'PCP_SA_IN', 'PCP_TN', 'PCP_SM', 'PCP_Z1', 'PCP_Z2',
'PCP_Z5','PAAC1_lam1']

X = data[rfe_cols]
y = data['Label']

# Split the data into training and testing sets (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Define the Bagging Classifier with a simpler base model (Decision Tree with limited depth)
bagging_model = BaggingClassifier(
    estimator=DecisionTreeClassifier(max_depth=5),  # Limiting the depth of base estimators
    n_estimators=50,  # Number of base estimators
    max_samples=0.8,  # Each base estimator uses 80% of the data
    max_features=0.8,  # Each base estimator uses 80% of the features
    random_state=42
)

# Fit the model to the training data
bagging_model.fit(X_train, y_train)

# Make predictions for training and testing data
y_train_pred = bagging_model.predict(X_train)
y_test_pred = bagging_model.predict(X_test)

# Calculate metrics for training and testing data
metrics = {}
for dataset, y_true, y_pred in [("Train", y_train, y_train_pred), ("Test", y_test, y_test_pred)]:
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    metrics[dataset] = {
        "Accuracy": accuracy_score(y_true, y_pred),
        "Precision": precision_score(y_true, y_pred),
        "Recall (Sensitivity)": recall_score(y_true, y_pred),
        "Specificity": tn / (tn + fp),
        "MCC": matthews_corrcoef(y_true, y_pred),
        "F1 Score": f1_score(y_true, y_pred)
    }

# Convert metrics to a DataFrame for better presentation
metrics_df = pd.DataFrame(metrics).T
metrics_df

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split

# Example dataset
data = 
X = data.data
y = data.target

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize ExtraTreesClassifier
etc = ExtraTreesClassifier(random_state=42)

# Define the hyperparameters grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

# Setup GridSearchCV
grid_search = GridSearchCV(estimator=etc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Fit the model
grid_search.fit(X_train, y_train)

# Best parameters
print(f"Best Parameters: {grid_search.best_params_}")

# Best score
print(f"Best Score: {grid_search.best_score_}")

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Example dataset
data = load_iris()
X = data.data
y = data.target

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize ExtraTreesClassifier
etc = ExtraTreesClassifier(random_state=42)

# Define the hyperparameters grid with adjustments for overfitting
param_grid = {
    'n_estimators': [50, 100, 150],  # Reduced number of estimators
    'max_depth': [None, 10, 20],  # Limiting the depth
    'min_samples_split': [5, 10],  # Increased min_samples_split
    'min_samples_leaf': [2, 4],  # Increased min_samples_leaf
    'max_features': ['auto', 'sqrt']
}

# Setup GridSearchCV
grid_search = GridSearchCV(estimator=etc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Fit the model
grid_search.fit(X_train, y_train)

# Best parameters
print(f"Best Parameters: {grid_search.best_params_}")

# Best score
print(f"Best Score: {grid_search.best_score_}")

# Evaluate on the test set
test_score = grid_search.score(X_test, y_test)
print(f"Test Set Score: {test_score}")



