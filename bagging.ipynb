{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall (Sensitivity)</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Data</th>\n",
       "      <td>0.991304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982758</td>\n",
       "      <td>0.991254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing Data</th>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.595478</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision  Recall (Sensitivity)  Specificity  \\\n",
       "Training Data  0.991304   1.000000              0.982659     1.000000   \n",
       "Testing Data   0.793103   0.857143              0.697674     0.886364   \n",
       "\n",
       "                    MCC  F1 Score  \n",
       "Training Data  0.982758  0.991254  \n",
       "Testing Data   0.595478  0.769231  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have a dataset with selected features (from randam features) we got by performing lgb and now we are doing baggy classifier on it\n",
    "# # Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "\n",
    "# storing the dataset in variable \n",
    "data = pd.read_csv('C:/Users/aashi/Downloads/Randam_Features.csv')\n",
    "\n",
    "#fixing X and y\n",
    "rfe_cols = ['Isoelectric_point', 'Aromaticity', 'AAC_C', 'AAC_G', 'AAC_H', 'AAC_N',\n",
    "'AAC_Y', 'PCP_NC', 'PCP_NE', 'PCP_AL', 'PCP_HB', 'PCP_SS_HE',\n",
    "'PCP_SA_EX', 'PCP_SA_IN', 'PCP_TN', 'PCP_SM', 'PCP_Z1', 'PCP_Z2',\n",
    "'PCP_Z5','PAAC1_lam1']\n",
    "\n",
    "X = data[rfe_cols]\n",
    "y = data['Label']\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize BaggingClassifier\n",
    "bagging_clf = BaggingClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on both training and testing data\n",
    "y_train_pred = bagging_clf.predict(X_train)\n",
    "y_test_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Define a function to calculate specificity\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# Calculate metrics for training data\n",
    "train_metrics = {\n",
    "    'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "    'Precision': precision_score(y_train, y_train_pred),\n",
    "    'Recall (Sensitivity)': recall_score(y_train, y_train_pred),\n",
    "    'Specificity': specificity_score(y_train, y_train_pred),\n",
    "    'MCC': matthews_corrcoef(y_train, y_train_pred),\n",
    "    'F1 Score': f1_score(y_train, y_train_pred)\n",
    "}\n",
    "\n",
    "# Calculate metrics for testing data\n",
    "test_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'Precision': precision_score(y_test, y_test_pred),\n",
    "    'Recall (Sensitivity)': recall_score(y_test, y_test_pred),\n",
    "    'Specificity': specificity_score(y_test, y_test_pred),\n",
    "    'MCC': matthews_corrcoef(y_test, y_test_pred),\n",
    "    'F1 Score': f1_score(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "# Combine results into a DataFrame for better visualization\n",
    "results_df = pd.DataFrame({'Training Data': train_metrics, 'Testing Data': test_metrics}).T\n",
    "\n",
    "# Display the results\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall (Sensitivity)</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.953623</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.947674</td>\n",
       "      <td>0.907303</td>\n",
       "      <td>0.954023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.795181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy  Precision  Recall (Sensitivity)  Specificity       MCC  \\\n",
       "Train  0.953623   0.948571              0.959538     0.947674  0.907303   \n",
       "Test   0.804598   0.825000              0.767442     0.840909  0.610289   \n",
       "\n",
       "       F1 Score  \n",
       "Train  0.954023  \n",
       "Test   0.795181  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/aashi/Downloads/Randam_Features.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#fixing X and y\n",
    "rfe_cols = ['Isoelectric_point', 'Aromaticity', 'AAC_C', 'AAC_G', 'AAC_H', 'AAC_N',\n",
    "'AAC_Y', 'PCP_NC', 'PCP_NE', 'PCP_AL', 'PCP_HB', 'PCP_SS_HE',\n",
    "'PCP_SA_EX', 'PCP_SA_IN', 'PCP_TN', 'PCP_SM', 'PCP_Z1', 'PCP_Z2',\n",
    "'PCP_Z5','PAAC1_lam1']\n",
    "\n",
    "X = data[rfe_cols]\n",
    "y = data['Label']\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define the Bagging Classifier with a simpler base model (Decision Tree with limited depth)\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=5),  # Limiting the depth of base estimators\n",
    "    n_estimators=50,  # Number of base estimators\n",
    "    max_samples=0.8,  # Each base estimator uses 80% of the data\n",
    "    max_features=0.8,  # Each base estimator uses 80% of the features\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for training and testing data\n",
    "y_train_pred = bagging_model.predict(X_train)\n",
    "y_test_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for training and testing data\n",
    "metrics = {}\n",
    "for dataset, y_true, y_pred in [(\"Train\", y_train, y_train_pred), (\"Test\", y_test, y_test_pred)]:\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics[dataset] = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall (Sensitivity)\": recall_score(y_true, y_pred),\n",
    "        \"Specificity\": tn / (tn + fp),\n",
    "        \"MCC\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# Convert metrics to a DataFrame for better presentation\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "139 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "401 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95833333 0.95\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95       0.95\n",
      " 0.95833333 0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95833333 0.95\n",
      " 0.95833333 0.95833333 0.95       0.95       0.95833333 0.95\n",
      " 0.95833333 0.95       0.95       0.95833333 0.95       0.95\n",
      " 0.95       0.95       0.95              nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.94166667 0.95833333 0.95\n",
      " 0.95833333 0.95833333 0.95       0.95       0.95833333 0.95\n",
      " 0.95833333 0.95       0.95       0.95833333 0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.94166667 0.95833333 0.95       0.95833333 0.95833333 0.95\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95       0.95\n",
      " 0.95833333 0.95       0.95       0.95       0.95       0.95\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95833333 0.95\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95       0.95\n",
      " 0.95833333 0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95833333 0.95\n",
      " 0.95833333 0.95833333 0.95       0.95       0.95833333 0.95\n",
      " 0.95833333 0.95       0.95       0.95833333 0.95       0.95\n",
      " 0.95       0.95       0.95              nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95833333 0.95\n",
      " 0.95833333 0.95833333 0.95       0.95       0.95833333 0.95\n",
      " 0.95833333 0.95       0.95       0.95833333 0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95833333 0.95\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95       0.95\n",
      " 0.95833333 0.95       0.95       0.95       0.95       0.95      ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example dataset\n",
    "data = \n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=etc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Best score\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best Score: 0.9583333333333334\n",
      "Test Set Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "180 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "96 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "84 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\aashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95833333 0.95833333 0.95833333 0.95       0.95833333 0.95\n",
      " 0.95833333 0.95       0.95       0.95       0.95       0.95\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95833333 0.95833333 0.95833333 0.95       0.95833333 0.95\n",
      " 0.95833333 0.95       0.95       0.95       0.95       0.95\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95833333 0.95833333 0.95833333 0.95       0.95833333 0.95\n",
      " 0.95833333 0.95       0.95       0.95       0.95       0.95      ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters grid with adjustments for overfitting\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Reduced number of estimators\n",
    "    'max_depth': [None, 10, 20],  # Limiting the depth\n",
    "    'min_samples_split': [5, 10],  # Increased min_samples_split\n",
    "    'min_samples_leaf': [2, 4],  # Increased min_samples_leaf\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=etc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Best score\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_score = grid_search.score(X_test, y_test)\n",
    "print(f\"Test Set Score: {test_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
